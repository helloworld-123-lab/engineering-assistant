import streamlit as st
import chromadb
from openai import OpenAI
import requests
import json
from typing import Dict, List, Generator
import re
import google.protobuf.message_factory as _mf
import base64
from io import BytesIO
import time
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np
import langid
from langcodes import Language
import os
import urllib.request
import py7zr

# https://protobuf.dev/news/v30/#remove-deprecated
if not hasattr(_mf.MessageFactory, "GetPrototype"):
    _mf.MessageFactory.GetPrototype = staticmethod(_mf.GetMessageClass)

# æ•°æ®åº“ä¸‹è½½å’Œè§£å‹å‡½æ•°
def download_and_extract_database():
    db_path = "chroma_db"
    zip_url = "https://raw.githubusercontent.com/helloworld-123-lab/engineering-assistant/main/chroma_db.7z"
    
    # å¦‚æœæ•°æ®åº“å·²ç»å­˜åœ¨ï¼Œç›´æ¥è¿”å›ï¼Œä¸æ˜¾ç¤ºä»»ä½•æ¶ˆæ¯
    if os.path.exists(db_path):
        return True
    
    # åªåœ¨éœ€è¦ä¸‹è½½æ—¶æ˜¾ç¤ºæ¶ˆæ¯
    with st.spinner("\næ­£åœ¨ä¸‹è½½æ•°æ®åº“æ–‡ä»¶ï¼Œè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ..."):
        try:
            # ä¸‹è½½æ–‡ä»¶
            urllib.request.urlretrieve(zip_url, "chroma_db.7z")
            
            # è§£å‹æ–‡ä»¶
            with py7zr.SevenZipFile("chroma_db.7z", mode='r') as z:
                z.extractall(path=".")
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            os.remove("chroma_db.7z")
            
            # è¿™é‡Œä¸æ˜¾ç¤ºæˆåŠŸæ¶ˆæ¯ï¼Œå› ä¸ºspinnerä¼šè‡ªåŠ¨æ¶ˆå¤±
            return True
            
        except Exception as e:
            st.error(f"æ•°æ®åº“æ–‡ä»¶ä¸‹è½½å¤±è´¥: {str(e)}")
            return False

# APIå¯†é’¥è·å–å‡½æ•°
def get_api_keys():
    """å®‰å…¨åœ°è·å–APIå¯†é’¥"""
    # ä¼˜å…ˆä»ç¯å¢ƒå˜é‡è·å–
    deepseek_key = os.environ.get("DEEPSEEK_API_KEY", "")
    siliconflow_key = os.environ.get("SILICONFLOW_API_KEY", "")
    p_key = os.environ.get("P_API_KEY", "")
    
    return deepseek_key, siliconflow_key,p_key

# é€šè¿‡ç¡…åŸºæµåŠ¨APIè·å–åµŒå…¥å‘é‡
def get_embeddings(texts: List[str], api_key: str) -> List[List[float]]:
    """
    é€šè¿‡ç¡…åŸºæµåŠ¨APIè·å–æ–‡æœ¬çš„åµŒå…¥å‘é‡
    """
    client = OpenAI(
        api_key=api_key,
        base_url="https://api.siliconflow.cn/v1"
    )
    
    try:
        # å¦‚æœæ˜¯å•ä¸ªæ–‡æœ¬ï¼Œè½¬æ¢ä¸ºåˆ—è¡¨
        if isinstance(texts, str):
            texts = [texts]
        
        # è°ƒç”¨åµŒå…¥æ¨¡å‹
        response = client.embeddings.create(
            model="Pro/BAAI/bge-m3",
            input=texts
        )
        
        # æå–åµŒå…¥å‘é‡
        embeddings = [item.embedding for item in response.data]
        return embeddings
        
    except Exception as e:
        st.error(f"è·å–åµŒå…¥å‘é‡å¤±è´¥: {str(e)}")
        # è¿”å›éšæœºå‘é‡ä½œä¸ºé™çº§æ–¹æ¡ˆ
        return [np.random.randn(1024).tolist() for _ in texts]

# åˆå§‹åŒ–ChromaDBå®¢æˆ·ç«¯ - é€‚é…Renderç¯å¢ƒ
@st.cache_resource
def get_chroma_collection():
    # ç¡®ä¿æ•°æ®åº“æ–‡ä»¶å­˜åœ¨
    if not download_and_extract_database():
        st.error("æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®åº“æ–‡ä»¶")
        return None
    
    try:
        client = chromadb.PersistentClient(path="chroma_db")
        collection = client.get_collection("my_collection")
        return collection
    except Exception as e:
        st.error(f"æ•°æ®åº“è¿æ¥å¤±è´¥: {str(e)}")
        return None

# è·å–å±‚çº§é€‰é¡¹ - ä¿®å¤å“ˆå¸Œé—®é¢˜
@st.cache_data
def get_level_options(_collection):
    # è·å–æ‰€æœ‰æ–‡æ¡£çš„å…ƒæ•°æ®æ¥æ„å»ºå±‚çº§é€‰é¡¹
    all_data = _collection.get(include=['metadatas'])
    metadatas = all_data['metadatas']

    course_tree = {}

    for metadata in metadatas:
        course = metadata.get('level_1')
        if not course:
            continue
        if course not in course_tree:
            course_tree[course] = {}

        node = course_tree[course]
        # åŠ¨æ€å¤„ç† level_2~level_5
        for level in ['level_2', 'level_3', 'level_4', 'level_5']:
            val = metadata.get(level)
            if val:
                if val not in node:
                    node[val] = {}
                node = node[val]
    return course_tree

def detect_user_language(text):
    """
    è¯­è¨€æ£€æµ‹å‡½æ•°
    """
    try:
        # æ£€æŸ¥æ˜¯å¦ä¸ºç©ºæˆ–è¿‡çŸ­çš„æ–‡æœ¬
        if not text or len(text.strip()) < 2:
            return "ä¸­æ–‡"  # é»˜è®¤è¯­è¨€
        
        # ä½¿ç”¨langidè¿›è¡Œè¯­è¨€æ£€æµ‹
        lang_code, confidence = langid.classify(text)
        
        # è¯­è¨€ä»£ç åˆ°ä¸­æ–‡åç§°çš„æ˜ å°„
        language_mapping = {
            'zh': 'ä¸­æ–‡',
            'en': 'è‹±æ–‡',
            'de': 'å¾·æ–‡',
            'fr': 'æ³•æ–‡',
            'es': 'è¥¿ç­ç‰™æ–‡',
            'it': 'æ„å¤§åˆ©æ–‡',
            'ja': 'æ—¥æ–‡',
            'ko': 'éŸ©æ–‡',
            'ru': 'ä¿„æ–‡',
            'pt': 'è‘¡è„ç‰™æ–‡',
            'nl': 'è·å…°æ–‡',
            'pl': 'æ³¢å…°æ–‡',
            'sv': 'ç‘å…¸æ–‡',
            'da': 'ä¸¹éº¦æ–‡',
            'no': 'æŒªå¨æ–‡',
            'fi': 'èŠ¬å…°æ–‡',
            'hu': 'åŒˆç‰™åˆ©æ–‡',
            'cs': 'æ·å…‹æ–‡',
            'el': 'å¸Œè…Šæ–‡',
            'tr': 'åœŸè€³å…¶æ–‡',
            'th': 'æ³°æ–‡',
            'vi': 'è¶Šå—æ–‡',
            'id': 'å°å°¼æ–‡',
            'ms': 'é©¬æ¥æ–‡',
            'hi': 'å°åœ°æ–‡',
            'ar': 'é˜¿æ‹‰ä¼¯æ–‡',
            'he': 'å¸Œä¼¯æ¥æ–‡',
            'fa': 'æ³¢æ–¯æ–‡'
        }
        
        # è¿”å›å¯¹åº”çš„è¯­è¨€åç§°ï¼Œå¦‚æœä¸åœ¨æ˜ å°„ä¸­åˆ™è¿”å›ä¸­æ–‡
        detected_language = language_mapping.get(lang_code, 'ä¸­æ–‡')
        
        # å¦‚æœç½®ä¿¡åº¦ä½äº0.5ï¼Œé»˜è®¤ä½¿ç”¨ä¸­æ–‡ï¼ˆç‰¹åˆ«æ˜¯å¯¹äºçŸ­æ–‡æœ¬ï¼‰
        # if confidence < 0.5:
        #     return "ä¸­æ–‡"
        
        # ç‰¹æ®Šå¤„ç†ï¼šä¸­æ–‡æ–‡æœ¬å¯èƒ½è¢«è¯¯è¯†åˆ«ä¸ºå…¶ä»–è¯­è¨€
        chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', text))
        total_chars = len(text)
        
        # å¦‚æœæ–‡æœ¬ä¸­è¶…è¿‡50%æ˜¯ä¸­æ–‡å­—ç¬¦ï¼Œå¼ºåˆ¶è¯†åˆ«ä¸ºä¸­æ–‡
        if total_chars > 0 and chinese_chars / total_chars > 0.5:
            return "ä¸­æ–‡"
            
        return detected_language
        
    except Exception as e:
        print(f"è¯­è¨€æ£€æµ‹å¤±è´¥: {e}")
        # å¤‡ç”¨æ£€æµ‹æ–¹æ³•ï¼šæ£€æŸ¥æ˜¯å¦åŒ…å«ä¸­æ–‡å­—ç¬¦
        if re.search(r'[\u4e00-\u9fff]', text):
            return "ä¸­æ–‡"
        return "ä¸­æ–‡"  # é»˜è®¤ä½¿ç”¨ä¸­æ–‡

# æµå¼è°ƒç”¨DeepSeek API
def call_deepseek_api_stream(question: str, context: str, api_key: str) -> Generator[str, None, None]:
    # å‡†ç¡®æ£€æµ‹ç”¨æˆ·è¯­è¨€
    user_language = detect_user_language(question)
    
    client = OpenAI(
        api_key=api_key, 
        base_url="https://api.deepseek.com/v1"
    )
    
    prompt = f"""ä½ æ˜¯ä¸€ä½å›½é™…åŒ–çš„å·¥ç¨‹æœºæ¢°é¢†åŸŸä¸“å®¶ã€‚è¯·åŸºäºä»¥ä¸‹èƒŒæ™¯èµ„æ–™å›ç­”é—®é¢˜ï¼š
    
    èƒŒæ™¯èµ„æ–™ï¼š
    {context}
    
    é—®é¢˜ï¼š{question}
    
    è¯·æ ¹æ®èƒŒæ™¯èµ„æ–™æä¾›å‡†ç¡®ã€ä¸“ä¸šã€æ¡ç†æ¸…æ™°çš„å›ç­”ã€‚å¦‚æœèµ„æ–™ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·è¯´æ˜æ— æ³•å›ç­”ã€‚
    
    é‡è¦è¦æ±‚ï¼š
    1. ç”¨æˆ·ä½¿ç”¨{user_language}æé—®ï¼Œå›å¤çš„å…¨éƒ¨å†…å®¹éƒ½å¿…é¡»ä½¿ç”¨ç›¸åŒçš„{user_language}è¿›è¡Œå›ç­”ï¼Œä¸è¦å¤¹æ‚å…¶ä»–è¯­è¨€æ–‡å­—ã€‚
    2. å›ç­”è¦ä¸“ä¸šã€å‡†ç¡®ã€æ˜“äºç†è§£ã€‚
    3. å¦‚æœèµ„æ–™ä¸è¶³ï¼Œè¯·æ˜ç¡®æŒ‡å‡ºã€‚
    4. ä¸ç®¡æ£€ç´¢åˆ°çš„èµ„æ–™æ˜¯ä»€ä¹ˆè¯­è¨€ï¼Œéƒ½å¿…é¡»æŠŠèµ„æ–™ç¿»è¯‘æˆ{user_language}ï¼Œå¿…é¡»ä½¿ç”¨{user_language}å›ç­”ï¼Œä¸å¾—ä½¿ç”¨å…¶ä»–è¯­è¨€ã€‚
    """

    messages=[
            {"role": "user", "content": prompt}
            ]
    
    try:
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=messages,
            temperature=0.7,
            max_tokens=2000,
            stream=True
        )

        for chunk in response:
            if chunk.choices and chunk.choices[0].delta.content:
                token = chunk.choices[0].delta.content
                yield token

    except Exception as e:
        yield f"åŠ©æ‰‹å‡ºé”™ï¼š{str(e)}"

# éæµå¼è°ƒç”¨DeepSeek API - ç”¨äºç”Ÿæˆæç¤ºè¯
def call_deepseek_api_non_stream(prompt: str, api_key: str) -> str:
    client = OpenAI(
        api_key=api_key, 
        base_url="https://api.deepseek.com/v1"
    )
    
    messages=[{"role": "user", "content": prompt}]
    
    try:
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=messages,
            temperature=0.7,
            max_tokens=500
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"ç”Ÿæˆæç¤ºè¯æ—¶å‡ºé”™ï¼š{str(e)}"

# ç”Ÿæˆå›¾ç‰‡æç¤ºè¯
def generate_image_prompt(content: str, image_type: str, api_key: str) -> str:
    """ç”Ÿæˆé€‚åˆå›¾ç‰‡ç”Ÿæˆçš„æç¤ºè¯"""
    prompt = f"""
    è¯·å°†ä»¥ä¸‹å·¥ç¨‹æœºæ¢°ç›¸å…³å†…å®¹è½¬æ¢ä¸ºé€‚åˆAIå›¾ç‰‡ç”Ÿæˆçš„æç¤ºè¯ï¼Œæ— è®ºåŸæ–‡å†…å®¹æ˜¯ä»€ä¹ˆè¯­è¨€ï¼Œè¦æ±‚ä¸€å®šè¦å°†è¾“å‡ºæ–‡ç”Ÿå›¾æç¤ºè¯è½¬æ¢ä¸ºè‹±æ–‡ï¼š
    
    åŸæ–‡å†…å®¹ï¼š
    {content}
    
    å›¾ç‰‡ç±»å‹ï¼š{image_type}
    
    è¦æ±‚ï¼š
    1. è‹±æ–‡æç¤ºè¯é•¿åº¦æ§åˆ¶åœ¨300å­—å·¦å³ã€‚
    2. åŒ…å«å…·ä½“çš„è§†è§‰å…ƒç´ ï¼šé¢œè‰²ã€æ„å›¾ã€ç»†èŠ‚ã€é£æ ¼ã€‚
    3. ä¸“æ³¨äºå·¥ç¨‹æœºæ¢°çš„æŠ€æœ¯ç‰¹ç‚¹å’Œå·¥ä½œåœºæ™¯ã€‚
    4. å¦‚æœæ˜¯ç¤ºæ„å›¾ï¼Œè¦çªå‡ºç»“æ„å’ŒåŸç†ã€‚
    5. å¦‚æœæ˜¯æ€ç»´å¯¼å›¾ï¼Œè¦ä½“ç°é€»è¾‘å…³ç³»å’Œå±‚æ¬¡ç»“æ„ã€‚
    
    è¯·ç›´æ¥è¾“å‡ºä¼˜åŒ–åçš„è‹±æ–‡å›¾ç‰‡ç”Ÿæˆæç¤ºè¯ï¼Œä¸è¦æ·»åŠ å…¶ä»–è§£é‡Šã€‚
    """
    
    return call_deepseek_api_non_stream(prompt, api_key)

# ç”ŸæˆMermaidå›¾è¡¨ä»£ç 
def generate_mermaid_code(content: str, api_key: str) -> str:
    """ç”ŸæˆMermaidè¯­æ³•è¡¨ç¤ºçš„æ€ç»´å¯¼å›¾æˆ–æµç¨‹å›¾"""
    prompt = f"""
    è¯·å°†ä»¥ä¸‹å·¥ç¨‹æœºæ¢°ç›¸å…³å†…å®¹è½¬æ¢ä¸ºMermaidè¯­æ³•ä»£ç ï¼Œå¦‚æœå†…å®¹æ˜¯éä¸­æ–‡çš„å°†å…¶è½¬æ¢æˆä¸­æ–‡ï¼š
    
    å†…å®¹ï¼š
    {content}
    
    è¦æ±‚ï¼š
    1. ä½¿ç”¨Mermaidçš„flowchart TDï¼ˆè‡ªä¸Šè€Œä¸‹æµç¨‹å›¾ï¼‰æˆ–mindmapï¼ˆæ€ç»´å¯¼å›¾ï¼‰è¯­æ³•
    2. æ ¹æ®å†…å®¹ç‰¹ç‚¹é€‰æ‹©æœ€é€‚åˆçš„å›¾è¡¨ç±»å‹
    3. ä¿æŒç»“æ„æ¸…æ™°ï¼Œå±‚æ¬¡åˆ†æ˜
    4. ä½¿ç”¨ç®€æ´çš„æ ‡ç­¾æè¿°
    5. åŒ…å«é€‚å½“çš„æ ·å¼å’Œé¢œè‰²
    6. è¾“å‡ºçº¯Mermaidä»£ç ï¼Œä¸è¦åŒ…å«å…¶ä»–è§£é‡Š
    
    Mermaidä»£ç ç¤ºä¾‹ï¼š
    ```mermaid
    mindmap
      root(å·¥ç¨‹æœºæ¢°)
        æŒ–æ˜æœº
          ç±»å‹
            å±¥å¸¦å¼
            è½®å¼
          å·¥ä½œåŸç†
            æ¶²å‹ç³»ç»Ÿ
            åŠ¨åŠ›ä¼ è¾“
    ```
    
    è¯·æ ¹æ®æä¾›çš„å†…å®¹ç”Ÿæˆåˆé€‚çš„Mermaidä»£ç ï¼š
    """
    
    return call_deepseek_api_non_stream(prompt, api_key)

# é€šè¿‡Kroki APIç”ŸæˆMermaidå›¾åƒ
def generate_mermaid_image(mermaid_code: str) -> Image.Image:
    """é€šè¿‡ Kroki API å°† Mermaid ä»£ç ç›´æ¥è½¬æ¢ä¸º PNG å›¾ç‰‡"""
    try:
        clean_code = mermaid_code.strip().replace('```mermaid', '').replace('```', '').strip()
        url = "https://kroki.io/mermaid/png"  # æ”¹ä¸º png

        response = requests.post(url, data=clean_code.encode('utf-8'))  # ç›´æ¥å‘é€æ–‡æœ¬ï¼Œä¸ç”¨ json
        if response.status_code == 200:
            return Image.open(BytesIO(response.content))
        else:
            print(f"Kroki API é”™è¯¯: {response.status_code} - {response.text}")
            return None

    except Exception as e:
        print(f"ç”Ÿæˆ Mermaid å›¾åƒæ—¶å‡ºé”™: {e}")
        return None

# ç”Ÿæˆå›¾ç‰‡ - æ”¯æŒå¤šç§æ¨¡å‹
def generate_image(prompt: str, model_type: str, api_key: str = None, api_key1: str = None) -> Image.Image:
    """
    æ ¹æ®é€‰æ‹©çš„æ¨¡å‹ç”Ÿæˆå›¾ç‰‡
    model_type: æ¨¡å‹ç±»å‹ï¼ŒåŒ…æ‹¬ 'kolors', 'flux', 'kontext', 'turbo', 'gptimage'
    """
    try:
        if model_type == 'kolors':
            # ä½¿ç”¨ç¡…åŸºæµåŠ¨çš„Kolorsæ¨¡å‹
            client = OpenAI(
                api_key=api_key, 
                base_url="https://api.siliconflow.cn/v1"
            )
            response = client.images.generate(
                model="Kwai-Kolors/Kolors",
                prompt=prompt,
                size="1024x1024",
                n=1,
                extra_body={"step": 20}
            )
            image_url = response.data[0].url
            # ä¸‹è½½å›¾ç‰‡
            image_response = requests.get(image_url)
            img = Image.open(BytesIO(image_response.content))
            return img
        
        elif model_type == 'flux' or model_type == 'turbo':
            # ä½¿ç”¨pollinations.aiçš„æ¨¡å‹
            # å¯¹promptè¿›è¡ŒURLç¼–ç 
            import urllib.parse
            encoded_prompt = urllib.parse.quote(prompt)
            
            # æ„å»ºpollinations.aiçš„URL
            pollinations_url = f"https://image.pollinations.ai/prompt/{encoded_prompt}?width=1024&height=1024&model={model_type}"
            
            # ä¸‹è½½å›¾ç‰‡
            image_response = requests.get(pollinations_url)
            if image_response.status_code == 200:
                img = Image.open(BytesIO(image_response.content))
                return img
            else:
                st.error(f"Pollinations API è¯·æ±‚å¤±è´¥: {image_response.status_code}")
                return None

        elif model_type == 'kontext' or model_type == 'gptimage':
            # ä½¿ç”¨pollinations.aiçš„æ¨¡å‹
            # å¯¹promptè¿›è¡ŒURLç¼–ç 
            import urllib.parse
            encoded_prompt = urllib.parse.quote(prompt)
            # æ„å»ºpollinations.aiçš„URL
            url = f"https://image.pollinations.ai/prompt/{encoded_prompt}?width=1024&height=1024&model={model_type}"
            headers = {"Authorization": f"Bearer {api_key1}"}
            # ä¸‹è½½å›¾ç‰‡
            image_response = requests.get(url, headers=headers)
            if image_response.status_code == 200:
                img = Image.open(BytesIO(image_response.content))
                st.success(f"âœ… {model_type.upper()}æ¨¡å‹å›¾ç‰‡ç”ŸæˆæˆåŠŸï¼")
                return img
            else:
                st.error(f"âŒ {model_type}æ¨¡å‹è¯·æ±‚å¤±è´¥: {image_response.status_code}")
                st.info(f"ğŸ’¡ æç¤ºï¼š{model_type}æ¨¡å‹è¿æ¥ä¸ç¨³å®šï¼Œå»ºè®®ç¨åé‡è¯•æˆ–é€‰æ‹©Kolors/Flux/Turboæ¨¡å‹")
                print(response.text)
                return None
                
    except Exception as e:
        st.error(f"å›¾ç‰‡ç”Ÿæˆå¤±è´¥: {str(e)}")
        return None

# æ„å»ºæŸ¥è¯¢è¿‡æ»¤å™¨
def build_where_filter(selected_levels: dict) -> dict:
    conditions = []
    for level, value in selected_levels.items():
        if value and value != "å…¨éƒ¨":
            conditions.append({level: {"$eq": value}})
    
    if not conditions:
        return None
    elif len(conditions) == 1:
        return conditions[0]
    else:
        return {"$and": conditions}

# æŸ¥è¯¢å‘é‡æ•°æ®åº“
def query_vector_db(question: str, _collection, siliconflow_api_key: str, selected_levels: Dict, n_results: int = 3):
    # é€šè¿‡APIè·å–æŸ¥è¯¢æ–‡æœ¬çš„åµŒå…¥å‘é‡
    query_embedding = get_embeddings(question, siliconflow_api_key)[0]
    
    where_filter = build_where_filter(selected_levels)
    
    results = _collection.query(
        query_embeddings=[query_embedding],
        n_results=n_results,
        where=where_filter,
        include=['documents', 'metadatas', 'distances']
    )
    
    return results

# æ¸…ç†æ–‡æœ¬æ˜¾ç¤º
def clean_text(text: str) -> str:
    text = re.sub(r'\s+', ' ', text)
    text = re.sub(r'[^\w\s\u4e00-\u9fffï¼Œã€‚ï¼ï¼Ÿï¼›ï¼š""''ï¼ˆï¼‰ã€ã€‘]', '', text)
    return text.strip()

# ä¸»åº”ç”¨
def main():
    st.set_page_config(
        page_title="å·¥ç¨‹æœºæ¢°çŸ¥è¯†åŠ©æ‰‹",
        page_icon="ğŸ”§",
        layout="wide"
    )
    
    st.title("ğŸ”§ å·¥ç¨‹æœºæ¢°çŸ¥è¯†åŠ©æ‰‹")
    st.markdown("åŸºäºå‘é‡æ•°æ®åº“çš„æ™ºèƒ½é—®ç­”ç³»ç»Ÿ")
    
    # åˆå§‹åŒ–session state
    if 'messages' not in st.session_state:
        st.session_state.messages = []
    if 'is_generating' not in st.session_state:
        st.session_state.is_generating = False
    if 'current_response' not in st.session_state:
        st.session_state.current_response = ""
    if 'streaming_placeholder' not in st.session_state:
        st.session_state.streaming_placeholder = None
    if 'generated_images' not in st.session_state:
        st.session_state.generated_images = {}
    if 'image_history' not in st.session_state:
        st.session_state.image_history = []
    if 'generating_image_type' not in st.session_state:
        st.session_state.generating_image_type = None
    if 'latest_illustration' not in st.session_state:
        st.session_state.latest_illustration = None
    if 'latest_mindmap' not in st.session_state:
        st.session_state.latest_mindmap = None
    if 'target_assistant_idx' not in st.session_state:    
        st.session_state.target_assistant_idx = None
        
    
    # é»˜è®¤å¯†é’¥
    DEFAULT_DEEPSEEK_API_KEY, DEFAULT_SILICONFLOW_API_KEY, P_API_KEY= get_api_keys()
    
    # åˆå§‹åŒ–èµ„æº
    try:
        collection = get_chroma_collection()
        if collection is None:
            st.error("æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®åº“æ–‡ä»¶é…ç½®")
            return
        level_options = get_level_options(collection)
    except Exception as e:
        st.error(f"åˆå§‹åŒ–å¤±è´¥: {e}")
        return
    
    # ä¾§è¾¹æ  - ç­›é€‰æ¡ä»¶
    with st.sidebar:
        st.header("ğŸ“ æ–‡æ¡£ç­›é€‰")
        level_names = {
            'level_1': 'ä¸€çº§åˆ†ç±»',
            'level_2': 'äºŒçº§åˆ†ç±»', 
            'level_3': 'ä¸‰çº§åˆ†ç±»',
            'level_4': 'å››çº§åˆ†ç±»',
            'level_5': 'äº”çº§åˆ†ç±»'
        }
        course_tree = level_options
    
        # é€‰æ‹©è¯¾ç¨‹
        courses = ["å…¨éƒ¨"] + list(course_tree.keys())
        selected_course = st.selectbox("é€‰æ‹©è¯¾ç¨‹", courses, key="level_1")
    
        selected_levels = {"level_1": selected_course}
    
        current_tree = course_tree.get(selected_course, {}) if selected_course != "å…¨éƒ¨" else {}
        for i, level in enumerate(['level_2','level_3','level_4','level_5']):
            if current_tree:
                options = ["å…¨éƒ¨"] + list(current_tree.keys())
                selected = st.selectbox(f"é€‰æ‹©{level}", options, key=level)
                selected_levels[level] = selected
                if selected != "å…¨éƒ¨":
                    current_tree = current_tree.get(selected, {})
                else:
                    current_tree = {}
            else:
                selected_levels[level] = "å…¨éƒ¨"
        
        st.markdown("---")
        st.header("ğŸ”§ è®¾ç½®")
        
        deepseek_api_key = st.text_input("DeepSeek API Keyï¼ˆç•™ç©ºä½¿ç”¨é»˜è®¤å€¼ï¼‰", type="password")
        if not deepseek_api_key:
            deepseek_api_key = DEFAULT_DEEPSEEK_API_KEY
            
        siliconflow_api_key = st.text_input("SiliconFlow API Keyï¼ˆç•™ç©ºä½¿ç”¨é»˜è®¤å€¼ï¼‰", type="password")
        if not siliconflow_api_key:
            siliconflow_api_key = DEFAULT_SILICONFLOW_API_KEY
        
        n_results = st.slider("æ£€ç´¢ç»“æœæ•°é‡", 1, 10, 3)
        
        # å›¾ç‰‡ç”Ÿæˆæ¨¡å‹é€‰æ‹©
        st.markdown("---")
        st.header("ğŸ¨ å›¾ç‰‡ç”Ÿæˆè®¾ç½®")
        
        image_model = st.selectbox(
            "é€‰æ‹©å›¾ç‰‡ç”Ÿæˆæ¨¡å‹",
            ["Kolors (ç¡…åŸºæµåŠ¨)", "Flux (Pollinations)", "Kontext (Pollinations)", "Turbo (Pollinations)", "GPTImage (Pollinations)"],
            index=0,
            help="é€‰æ‹©ç”¨äºç”Ÿæˆå›¾ç‰‡çš„AIæ¨¡å‹\n\næ³¨æ„ï¼šKontextå’ŒGPTImageæ¨¡å‹ç”Ÿæˆæ—¶é—´è¾ƒé•¿ä¸”è¿æ¥ä¸ç¨³å®š"
        )

        # å¦‚æœé€‰æ‹©äº†Kontextæˆ–GPTImageï¼Œæ˜¾ç¤ºè­¦å‘Š
        if image_model in ["Kontext (Pollinations)", "GPTImage (Pollinations)"]:
            st.warning("âš ï¸ æ³¨æ„ï¼šKontextå’ŒGPTImageæ¨¡å‹ç”Ÿæˆå›¾ç‰‡æ—¶é—´è¾ƒé•¿ï¼Œè¿æ¥ä¸ç¨³å®šï¼Œå¦‚æœè¯·æ±‚ä¸æˆåŠŸå¯ç¨åé‡è¯•æˆ–é€‰æ‹©å…¶ä»–æ¨¡å‹")
        
        # å°†æ˜¾ç¤ºåç§°æ˜ å°„åˆ°æ¨¡å‹æ ‡è¯†ç¬¦
        model_mapping = {
            "Kolors (ç¡…åŸºæµåŠ¨)": "kolors",
            "Flux (Pollinations)": "flux",
            "Kontext (Pollinations)": "kontext", 
            "Turbo (Pollinations)": "turbo",
            "GPTImage (Pollinations)": "gptimage"
        }
        
        selected_image_model = model_mapping[image_model]
        
        st.markdown("---")
        st.header("ğŸ—‚ï¸ å¯¹è¯ç®¡ç†")
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯", use_container_width=True, disabled=st.session_state.is_generating):
            st.session_state.messages = []
            st.session_state.current_response = ""
            st.session_state.is_generating = False
            st.session_state.streaming_placeholder = None
            st.session_state.generated_images = {}
            st.session_state.image_history = []
            st.session_state.generating_image_type = None
            st.session_state.latest_illustration = None
            st.session_state.latest_mindmap = None
            st.session_state.target_assistant_idx = None
            st.rerun()
        
        # æ˜¾ç¤ºæ•°æ®åº“ä¿¡æ¯
        st.markdown("---")
        st.header("ğŸ“Š æ•°æ®åº“ä¿¡æ¯")
        total_docs = collection.count()
        st.write(f"æ€»æ–‡æ¡£æ•°: {total_docs}")
        
        # æ˜¾ç¤ºå½“å‰ç­›é€‰æ¡ä»¶
        st.subheader("ğŸ” å½“å‰ç­›é€‰")
        active_filters = {name: selected_levels[key] for key, name in level_names.items() 
                         if selected_levels[key] and selected_levels[key] != "å…¨éƒ¨"}
        
        if active_filters:
            for name, value in active_filters.items():
                st.write(f"**{name}:** {value}")
        else:
            st.write("å…¨éƒ¨æ–‡æ¡£")
    
    # ä¸»åŒºåŸŸ - èŠå¤©ç•Œé¢è®¾è®¡
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("ğŸ’¬ å¯¹è¯")
        
        # æ˜¾ç¤ºèŠå¤©å†å²
        for idx, message in enumerate(st.session_state.messages):
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
                
                # æ˜¾ç¤ºç”Ÿæˆçš„å›¾ç‰‡ï¼ˆå¦‚æœæœ‰ï¼‰
                if message["role"] == "assistant" and str(idx) in st.session_state.generated_images:
                    images_dict = st.session_state.generated_images[str(idx)]
                    # æ˜¾ç¤ºç¤ºæ„å›¾
                    if "illustration" in images_dict:
                        image_data, prompt, model_info = images_dict["illustration"]
                        st.image(image_data, caption=f"ç”Ÿæˆçš„ç¤ºæ„å›¾ - {model_info}", use_container_width=True)
                    # æ˜¾ç¤ºæ€ç»´å¯¼å›¾
                    if "mindmap" in images_dict:
                        image_data, prompt = images_dict["mindmap"]
                        st.image(image_data, caption="ç”Ÿæˆçš„æ€ç»´å¯¼å›¾/æµç¨‹å›¾", use_container_width=True)
                
                # æ˜¾ç¤ºç›¸å…³æ–‡æ¡£ï¼ˆå¦‚æœæœ‰ï¼‰
                if message["role"] == "assistant" and "documents" in message and message["documents"]:
                    with st.expander(f"ğŸ“„ æŸ¥çœ‹ç›¸å…³æ–‡æ¡£ ({len(message['documents'])} æ¡)", expanded=False):
                        for i, doc in enumerate(message["documents"], 1):
                            data = doc['data']
                            st.markdown(f"**æ–‡æ¡£ {i}** (ç›¸ä¼¼åº¦: {1-doc.get('distance', 0):.3f})")
                            st.markdown(f"**å†…å®¹**: {clean_text(data.get('document', 'æœªçŸ¥'))}")
                            if doc.get('metadata'):
                                metadata = doc['metadata']
                                for key, value in metadata.items():
                                    if value and value != "å…¨éƒ¨":
                                        st.markdown(f"**{key}**: {value}")
                            st.markdown("---")
        
            # å¦‚æœå½“å‰æ¶ˆæ¯æ˜¯æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ä¸”æ­£åœ¨ç”Ÿæˆï¼Œåˆ™åœ¨å®ƒä¸‹é¢æ˜¾ç¤ºå ä½ç¬¦
            if idx == len(st.session_state.messages) - 1 and st.session_state.is_generating:
                if st.session_state.streaming_placeholder is None:
                    st.session_state.streaming_placeholder = st.empty()
                st.session_state.streaming_placeholder.markdown(st.session_state.current_response + "â–Œ")
    
    with col2:
        st.subheader("ğŸ“Š æ£€ç´¢ä¿¡æ¯")
        
        # æ˜¾ç¤ºæœ€è¿‘ä¸€æ¬¡æ£€ç´¢çš„ä¿¡æ¯
        if st.session_state.messages and not st.session_state.is_generating:
            last_message = st.session_state.messages[-1]
            if last_message["role"] == "assistant" and "documents" in last_message:
                documents = last_message["documents"]
                
                st.metric("æ£€ç´¢æ–‡æ¡£æ•°", len(documents))
                
                # æ˜¾ç¤ºç›¸ä¼¼åº¦åˆ†å¸ƒ
                if documents:
                    st.subheader("ğŸ“ˆ ç›¸ä¼¼åº¦åˆ†æ")
                    similarities = [1 - doc.get('distance', 0) for doc in documents]
                    avg_similarity = sum(similarities) / len(similarities)
                    st.metric("å¹³å‡ç›¸ä¼¼åº¦", f"{avg_similarity:.3f}")
                    
                    # æ˜¾ç¤ºæ¯ä¸ªæ–‡æ¡£çš„ç›¸ä¼¼åº¦
                    for i, similarity in enumerate(similarities):
                        # ç¡®ä¿ç›¸ä¼¼åº¦åœ¨ 0.0 åˆ° 1.0 ä¹‹é—´
                        if similarity < 0.0:
                            progress_value = 0.0
                        elif similarity > 1.0:
                            progress_value = 1.0
                        else:
                            progress_value = similarity
                        
                        st.progress(progress_value, text=f"æ–‡æ¡£ {i+1}: {similarity:.3f}")

        # ç”ŸæˆçŠ¶æ€æŒ‡ç¤ºå™¨
        if st.session_state.is_generating:
            st.info("ğŸ”„ æ­£åœ¨ç”Ÿæˆå›ç­”ï¼Œè¯·ç¨å€™...")
        
        # åœ¨å³ä¾§åº•éƒ¨æ·»åŠ å›¾ç‰‡å±•ç¤ºåŒºåŸŸ
        st.markdown("---")
        st.subheader("ğŸ¨ ç”Ÿæˆçš„å›¾ç‰‡")
        
        # æ˜¾ç¤ºå›¾ç‰‡ç”ŸæˆçŠ¶æ€
        if st.session_state.generating_image_type:
            image_type_name = "ç¤ºæ„å›¾" if st.session_state.generating_image_type == "illustration" else "æ€ç»´å¯¼å›¾/æµç¨‹å›¾"
            st.info(f"ğŸ¨ æ­£åœ¨ç”Ÿæˆ{image_type_name}ï¼Œè¯·ç¨å€™...")
        
        # æ˜¾ç¤ºæœ€æ–°å›¾ç‰‡
        col_illus, col_mind = st.columns(2)
        
        with col_illus:
            st.subheader("æœ€æ–°ç¤ºæ„å›¾")
            if st.session_state.latest_illustration:
                image_data, prompt, model_info = st.session_state.latest_illustration
                st.image(image_data, caption=f"æ¨¡å‹: {model_info}", use_container_width=True)
            else:
                st.info("æš‚æ— ç¤ºæ„å›¾")
        
        with col_mind:
            st.subheader("æœ€æ–°æ€ç»´å¯¼å›¾")
            if st.session_state.latest_mindmap:
                image_data, prompt = st.session_state.latest_mindmap
                st.image(image_data, use_container_width=True)
            else:
                st.info("æš‚æ— æ€ç»´å¯¼å›¾")
        
        # æ˜¾ç¤ºå†å²å›¾ç‰‡
        if st.session_state.image_history:
            st.markdown("---")
            st.subheader("ğŸ“š å†å²å›¾ç‰‡")
            
            # æŒ‰ç±»å‹åˆ†ç»„æ˜¾ç¤ºå†å²å›¾ç‰‡
            history_illustrations = [item for item in st.session_state.image_history if item[2] == "illustration"]
            history_mindmaps = [item for item in st.session_state.image_history if item[2] == "mindmap"]
            
            if history_illustrations:
                st.markdown("#### å†å²ç¤ºæ„å›¾")
                cols = st.columns(min(3, len(history_illustrations)))
                for idx, (img_data, prompt, img_type, model_info) in enumerate(history_illustrations[-3:]):  # åªæ˜¾ç¤ºæœ€è¿‘3å¼ 
                    with cols[idx]:
                        thumbnail = img_data.copy()
                        thumbnail.thumbnail((100, 100))
                        st.image(thumbnail, caption=f"æ¨¡å‹: {model_info}", use_container_width=True)
            
            if history_mindmaps:
                st.markdown("#### å†å²æ€ç»´å¯¼å›¾")
                cols = st.columns(min(3, len(history_mindmaps)))
                for idx, (img_data, prompt, img_type) in enumerate(history_mindmaps[-3:]):  # åªæ˜¾ç¤ºæœ€è¿‘3å¼ 
                    with cols[idx]:
                        thumbnail = img_data.copy()
                        thumbnail.thumbnail((100, 100))
                        st.image(thumbnail, use_container_width=True)
    
    # è¾“å…¥æ¡†å’Œå›¾ç‰‡ç”ŸæˆæŒ‰é’®
    st.markdown("---")
    
    input_container = st.container()
    with input_container:
        col_input1, col_input2, col_input3 = st.columns([4, 1, 1])
        
        with col_input1:
            # èŠå¤©è¾“å…¥æ¡†
            prompt = st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜...")
            
            if prompt:
                question = prompt
                st.session_state.messages.append({"role": "user", "content": question})
                st.session_state.is_generating = True
                st.session_state.current_response = ""
                st.session_state.streaming_placeholder = None
                st.rerun()
        
        with col_input2:
            # ç”Ÿæˆç¤ºæ„å›¾æŒ‰é’®
            illustration_disabled = (
                st.session_state.is_generating or 
                not st.session_state.messages or 
                st.session_state.generating_image_type is not None
            )
            
            if st.button("ğŸ¨ ç”Ÿæˆç¤ºæ„å›¾", disabled=not st.session_state.messages, use_container_width=True):
                assistant_indices = [i for i, m in enumerate(st.session_state.messages) if m["role"] == "assistant"]
                if assistant_indices:
                    st.session_state.generating_image_type = "illustration"
                    st.session_state.target_assistant_idx = assistant_indices[-1]
                    st.rerun()
        
        with col_input3:
            # ç”Ÿæˆæ€ç»´å¯¼å›¾æŒ‰é’®
            mindmap_disabled = (
                st.session_state.is_generating or 
                not st.session_state.messages or 
                st.session_state.generating_image_type is not None
            )
            
            if st.button("ğŸ“Š ç”Ÿæˆæ€ç»´å¯¼å›¾", disabled=not st.session_state.messages, use_container_width=True):
                assistant_indices = [i for i, m in enumerate(st.session_state.messages) if m["role"] == "assistant"]
                if assistant_indices:
                    st.session_state.generating_image_type = "mindmap"
                    st.session_state.target_assistant_idx = assistant_indices[-1]
                    st.rerun()

    # å¤„ç†å›¾ç‰‡ç”Ÿæˆ
    if st.session_state.generating_image_type and st.session_state.target_assistant_idx is not None:
        idx = st.session_state.target_assistant_idx
        response_text = st.session_state.messages[idx]["content"]
                
        if idx is not None:
            with st.spinner("æ­£åœ¨ç”Ÿæˆå›¾ç‰‡ï¼Œè¯·ç¨å€™..."):
                try:
                    if st.session_state.generating_image_type == "illustration":
                        # ç”Ÿæˆç¤ºæ„å›¾
                        image_prompt = generate_image_prompt(response_text, "ç®€æ´æ˜äº†çš„æŠ€æœ¯ç¤ºæ„å›¾", deepseek_api_key)
                        if not image_prompt.startswith("ç”Ÿæˆæç¤ºè¯æ—¶å‡ºé”™"):
                            # æ ¹æ®é€‰æ‹©çš„æ¨¡å‹ç”Ÿæˆå›¾ç‰‡
                            image_data = generate_image(image_prompt, selected_image_model, siliconflow_api_key, P_API_KEY)
                            if image_data:
                                # ä¿å­˜åˆ°å½“å‰æ¶ˆæ¯
                                st.session_state.generated_images.setdefault(str(idx), {})
                                # ä¿å­˜å›¾ç‰‡æ•°æ®å’Œæ¨¡å‹ä¿¡æ¯
                                model_display_name = {
                                    "kolors": "Kolors (ç¡…åŸºæµåŠ¨)",
                                    "flux": "Flux (Pollinations)",
                                    "kontext": "Kontext (Pollinations)",
                                    "turbo": "Turbo (Pollinations)", 
                                    "gptimage": "GPTImage (Pollinations)"
                                }
                                model_info = model_display_name.get(selected_image_model, selected_image_model)
                                
                                st.session_state.generated_images[str(idx)]["illustration"] = (image_data, image_prompt, model_info)
                                
                                # æ›´æ–°æœ€æ–°ç¤ºæ„å›¾
                                st.session_state.latest_illustration = (image_data, image_prompt, model_info)
                                
                                # æ·»åŠ åˆ°å†å²è®°å½•
                                st.session_state.image_history.append((image_data, image_prompt, "illustration", model_info))
                                st.success(f"ç¤ºæ„å›¾ç”ŸæˆæˆåŠŸï¼ä½¿ç”¨æ¨¡å‹: {model_info}")
                                
                    elif st.session_state.generating_image_type == "mindmap":
                        # ç”Ÿæˆæ€ç»´å¯¼å›¾
                        mermaid_code = generate_mermaid_code(response_text, deepseek_api_key)
                        if not mermaid_code.startswith("ç”Ÿæˆæç¤ºè¯æ—¶å‡ºé”™"):
                            image_data = generate_mermaid_image(mermaid_code)
                            if image_data:
                                st.session_state.generated_images.setdefault(str(idx), {})
                                st.session_state.generated_images[str(idx)]["mindmap"] = (image_data, mermaid_code)
                                # æ›´æ–°æœ€æ–°æ€ç»´å¯¼å›¾
                                st.session_state.latest_mindmap = (image_data, mermaid_code)
                                    
                                # æ·»åŠ åˆ°å†å²è®°å½•
                                st.session_state.image_history.append((image_data, mermaid_code, "mindmap"))
                                st.success("æ€ç»´å¯¼å›¾ç”ŸæˆæˆåŠŸï¼")
                            else:
                                st.error("æ€ç»´å¯¼å›¾ç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥Mermaidä»£ç æˆ–é‡è¯•")
                        else:
                            st.error(f"ç”Ÿæˆæ€ç»´å¯¼å›¾ä»£ç å¤±è´¥: {mermaid_code}")
                
                except Exception as e:
                    st.error(f"å›¾ç‰‡ç”Ÿæˆå¤±è´¥: {str(e)}")
                
                finally:
                    st.session_state.generating_image_type = None
                    st.rerun()

    # å¤„ç†æ¶ˆæ¯ç”Ÿæˆ
    if st.session_state.is_generating and st.session_state.messages and st.session_state.messages[-1]["role"] == "user":
        user_question = st.session_state.messages[-1]["content"]
        
        try:
            # æŸ¥è¯¢å‘é‡æ•°æ®åº“
            results = query_vector_db(user_question, collection, siliconflow_api_key, selected_levels, n_results)
            
            # å¤„ç†æ£€ç´¢ç»“æœ
            documents_data = []
            if results['documents'] and results['documents'][0]:
                context = "\n\n".join(results['documents'][0])
                sources = results['documents'][0]
                distances = results['distances'][0]
                metadatas = results['metadatas'][0] if results['metadatas'] else []
                
                # æ„å»ºæ–‡æ¡£æ•°æ®
                for i, (source, distance) in enumerate(zip(sources, distances)):
                    doc_data = {
                        'data': {'document': source},
                        'distance': distance,
                        'metadata': metadatas[i] if i < len(metadatas) else {}
                    }
                    documents_data.append(doc_data)
            else:
                context = "æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£ã€‚"
                documents_data = []
            
            # æµå¼è¾“å‡º
            full_response = ""
            
            for chunk in call_deepseek_api_stream(user_question, context, deepseek_api_key):
                full_response += chunk
                st.session_state.current_response = full_response
                if st.session_state.streaming_placeholder is not None:
                    st.session_state.streaming_placeholder.markdown(full_response + "â–Œ")
            
            if st.session_state.streaming_placeholder is not None:
                st.session_state.streaming_placeholder.markdown(full_response)
            
            # å°†åŠ©æ‰‹æ¶ˆæ¯æ·»åŠ åˆ°èŠå¤©å†å²
            st.session_state.messages.append({
                "role": "assistant", 
                "content": full_response,
                "documents": documents_data
            })
            
        except Exception as e:
            error_response = f"å¤„ç†é—®é¢˜æ—¶å‡ºé”™: {str(e)}"
            st.session_state.messages.append({
                "role": "assistant", 
                "content": error_response,
                "documents": []
            })
        
        finally:
            st.session_state.is_generating = False
            st.session_state.current_response = ""
            st.session_state.streaming_placeholder = None
            st.rerun()

if __name__ == "__main__":
    main()
